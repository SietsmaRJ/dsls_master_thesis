{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing some shizzle.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import time\n",
    "import requests\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import math\n",
    "\n",
    "# Defining some import and export locations\n",
    "location = 'rjsietsma'\n",
    "read_loc = '/home/'+location+'/Documents/School/Master_DSLS/Final_Thesis/Initial_Data_exploration/'\n",
    "data_expor_loc = '/home/'+location+'/Documents/School/Master_DSLS/Final_Thesis/Past_initial_data/'\n",
    "img_output_dir = '/home/'+location+'/PycharmProjects/dsls_master_thesis/side_scripts/output_img/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to perform Shapiro-Wilk, Kolmogorov-Smirnov, Wilcoxon-/Mann-Whitney U -test, and a pearson correlation test.\n",
    "\n",
    "def perform_stats(x, y):\n",
    "    shapiro_x = stats.shapiro(x)[1]\n",
    "    shapiro_y = stats.shapiro(y)[1]\n",
    "    if shapiro_x >= 0.05:\n",
    "        print(\"X is likely normally distributed.\")\n",
    "    else:\n",
    "        print(\"X is likely not normally distributed.\")\n",
    "    if shapiro_y >= 0.05:\n",
    "        print(\"Y is likely normally distributed.\")\n",
    "    else:\n",
    "        print(\"Y is likely not normally distributed.\")\n",
    "    try:\n",
    "        p_ks_xy = stats.ks_2samp(x, y)[1]\n",
    "        print(f\"The Kolmogorov-Smirnov test p-value: {p_ks_xy}\")\n",
    "    except Exception:\n",
    "        print(\"Kolmogorov-Smirnov could not be performed!\")\n",
    "    try:\n",
    "        p_wc_xy = stats.wilcoxon(x, y)[1]\n",
    "        print(f\"The Wilcoxon test p-value: {p_wc_xy}\")\n",
    "    except ValueError:\n",
    "        p_mw_xy = stats.mannwhitneyu(x, y)[1]\n",
    "        print(f\"Wilcoxon could not be performed, \\n\"\n",
    "             f\"Using Mann-Whitney rank test p-value: {p_mw_xy}\")\n",
    "    except Exception:\n",
    "        print(\"Neither Wilcoxon nor Mann-Whitney tests could be performed!\")\n",
    "    try:\n",
    "        p_pears_xy = stats.pearsonr(x, y)\n",
    "        print(f\"The Pearson correlation: {p_pears_xy[0]},\\n\"\n",
    "             f\"p-value: {p_pears_xy[1]}\")\n",
    "    except Exception:\n",
    "        print(\"Pearson correlation could not be performed!\")\n",
    "\n",
    "# Define function to calculate the Z-scores of given data.\n",
    "\n",
    "def calc_z_scores(data):\n",
    "    centered = data - data.mean(axis=0)\n",
    "    return centered / centered.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprint 28-04-2020 - 19-05-2020 (?)\n",
    "=====================\n",
    "\n",
    "- What I want to do:\n",
    "  1. [Focus on fixing missing CAPICE precomputed scores.](#Fixing-CAPICE-precomputed-scores)\n",
    "      - _Note: Find out how the script of Shuang works on a smaller scale, get an example where a CAPICE score is missing._\n",
    "  2. [Normalize BM_ratio](#Normalize-BM_ratio) for gene length, so $\\frac{n_{malignant}}{n_{benign}}$ per 1000 bases in a gene, instead of [$\\frac{n_{malign}}{n_{benign}} \\times n_{total}$](output_img/bm_ratio.png \"BM_ratio\").\n",
    "  3. _(questionable)_ Fix PCA by identifying categorical features _(Questionable because should I still put time and focus in on the input data?)_\n",
    "      - _Ask Shuang, Joeri and Krista in the PRU 28-04-2020 @ 13:00-14:00_\n",
    "  4. [See what is required](#Required-for-data-sources) for the [data sources](https://docs.google.com/document/d/1D5SiNbeDEfY2hTWquS88MGUrLv6IgZzfCzflppRGb5k/edit) to be implemented into the input data.\n",
    "      - _Note: as this is research, I can use sources that only have precomputed scores available, but just to keep in mind that I should mention that in the discussion._\n",
    "\n",
    "- Notes:\n",
    "  - If I find myself unfocussed:\n",
    "      - Win a game of [solitaire](https://play.google.com/store/apps/details?id=com.lemongame.klondike.solitaire&hl=nl) (game is rigged, not every match is win-able).\n",
    "      - Clean out my closet (it's messy, maybe to clean up the mess inside my head too).\n",
    "      - Go for a walk around the neighbourhood.\n",
    "\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "### Fixing CAPICE precomputed scores\n",
    "\n",
    "Problem: CAPICE precomputed file of all single nucleotide level variants contains caps.\n",
    "\n",
    "Solution: Fix the underlying problem that causes these gaps.\n",
    "\n",
    "Required: \n",
    "- Script to make and batch the CAPICE computing __(positive check)__\n",
    "- Access to GCC cluster __(positive check)__\n",
    "- Knowledge of job scheduler on GCC cluster \n",
    "- Smaller batches of SNV files to run locally \n",
    "\n",
    "Possible cause:\n",
    "- Incorrect batching on tabix.\n",
    "\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "### Normalize BM_ratio\n",
    "\n",
    "Problem: Larger genes have more benign and malignant samples, because they are larger and thus the chanses of variation on the reference read is higher.\n",
    "\n",
    "Solution: Make a $n_{malignant}$ and $n_{benign}$ per $x$ bases in a gene, where {$x \\in \\mathbb{N}\\ | x \\geq 1 | x \\leq 10000$}\n",
    "\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "### Required for data sources\n",
    "\n",
    "Problem: Now that a lot of data sources have been found, annotation and merging has to be performed in order to use it as training data.\n",
    "- _Additional problem: once a source has been proven beneficial, it has te be implemented to be annotated before capice fits and predicts a new sample._\n",
    "\n",
    "Solution: Find out, feature by feature if genes that have a low AUC improve *__and that genes that have a high AUC do not perform worse__*\n",
    "\n",
    "Required:\n",
    "- Storage \n",
    "    - On GCC cluster for precomputed score files.\n",
    "    - Locally IF file isn't that big or an API can be used.\n",
    "- Data sources __([positive check](https://docs.google.com/document/d/1D5SiNbeDEfY2hTWquS88MGUrLv6IgZzfCzflppRGb5k/edit))__\n",
    "- Script to annotate / merge\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTEPG (Catching The Elusive Predictable Genes) 28-04-2020 - 04-05-2020\n",
    "<br/><br/>\n",
    "\n",
    "What have I done:\n",
    "\n",
    "- [Enrichr Genes < 0.6](https://amp.pharm.mssm.edu/Enrichr/enrich?dataset=b7a959357214069d1905719220ed3e3b)\n",
    "- [Enrichr Genes < 0.7](https://amp.pharm.mssm.edu/Enrichr/enrich?dataset=7d252a3e1df275859228fd562e964344)\n",
    "    - For reference: [Enrichr Genes < 0.85](https://amp.pharm.mssm.edu/Enrichr/enrich?dataset=60c74741c967c25331419bd2b5e7183e)\n",
    "- [Finished investigating initial data sources](https://docs.google.com/document/d/1D5SiNbeDEfY2hTWquS88MGUrLv6IgZzfCzflppRGb5k/edit)\n",
    "\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "\n",
    "What I'm planning to do this week:\n",
    "\n",
    "- [Fixing missing values in precomputed CAPICE scoring file](#Fixing-CAPICE-precomputed-scores).\n",
    "    - If stuck, do not keep walking into the wall, continue below and contact Shuang and Joeri\n",
    "- Run enrichr on increasing cutoffs in AUC (.5, .6, .7 etc.).\n",
    "    - Read into the [Enrichr API documentation](https://amp.pharm.mssm.edu/Enrichr/help#api)\n",
    "- Make [suggested plot](https://docs.google.com/presentation/d/1_woKoD9nqWnxueyFYfwyX6B4owg8vYF7rw_nKpMPux4/edit#slide=id.p).\n",
    "    - Select from enrichr all the genes involved in (lipid) metabolism and see if this explains all / most of the bad performing genes.\n",
    "- Make model on bad performing genes and investigate further.\n",
    "- Start investigating what is required for the data sources to be used in the training phase.\n",
    "- Look into the genes that do perform well without a CGD category, also look into the 1/2 genes that do not perform well __with__ a CGD category\n",
    "- _Optionally_ :\n",
    "    - Create outline for article.\n",
    "    - Adjust BM_ratio plot to normalize for gene length.\n",
    "    - Get the UMCG gene panel lists into python\n",
    "        - Then: investigate which gene panel is performing the worst.\n",
    "        - It would be nice to have this on the side for diagnostics, do __not__ focus on this\n",
    "    - Fix PCA.\n",
    "    - Find possible way to annotate genes for co-factors, sub-family etc.\n",
    " \n",
    "\n",
    "  \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
